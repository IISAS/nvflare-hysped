services:

  server1:
    container_name: server1
    build:
      context: ./nvflare_compose
      dockerfile: Dockerfile
    image: ${DOCKER_IMAGE_SERVER}
    command:
    - /usr/local/bin/python
    - -u
    - -m
    - nvflare.private.fed.app.server.server_train
    - -m
    - /workspace
    - -s
    - fed_server.json
    - --set
    - secure_train=true
    - config_folder=config
    - org=nvidia
    ports:
    - 8002:8002
    - 8003:8003
    volumes:
    - ./server1:/workspace
    - nvflare_svc_persist:/tmp/nvflare/


  site-1:
    container_name: site-1
    build:
      context: ./nvflare_compose
      dockerfile: Dockerfile
    image: ${DOCKER_IMAGE_SITE}
    ulimits:
      memlock: -1
      stack: 67108864
    environment:
      - TF_FORCE_GPU_ALLOW_GROWTH=${TF_FORCE_GPU_ALLOW_GROWTH}
      - TF_GPU_MEMORY_LIMIT=${TF_GPU_MEMORY_LIMIT}
      - TF_GPU_ALLOCATOR=cuda_malloc_async
    command:
    - /usr/local/bin/python
    - -u
    - -m
    - nvflare.private.fed.app.client.client_train
    - -m
    - /workspace
    - -s
    - fed_client.json
    - --set
    - secure_train=true
    - uid=site-1
    - org=nvidia
    - config_folder=config
    volumes:
    - ./site-1:/workspace
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]


  site-2:
    container_name: site-2
    build:
      context: ./nvflare_compose
      dockerfile: Dockerfile
    image: ${DOCKER_IMAGE_SITE}
    ulimits:
      memlock: -1
      stack: 67108864
    environment:
      - TF_FORCE_GPU_ALLOW_GROWTH=${TF_FORCE_GPU_ALLOW_GROWTH}
      - TF_GPU_MEMORY_LIMIT=${TF_GPU_MEMORY_LIMIT}
      - TF_GPU_ALLOCATOR=cuda_malloc_async
    command:
    - /usr/local/bin/python
    - -u
    - -m
    - nvflare.private.fed.app.client.client_train
    - -m
    - /workspace
    - -s
    - fed_client.json
    - --set
    - secure_train=true
    - uid=site-2
    - org=nvidia
    - config_folder=config
    volumes:
    - ./site-2:/workspace
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]


  site-3:
    container_name: site-3
    build:
      context: ./nvflare_compose
      dockerfile: Dockerfile
    image: ${DOCKER_IMAGE_SITE}
    ulimits:
      memlock: -1
      stack: 67108864
    environment:
      - TF_FORCE_GPU_ALLOW_GROWTH=${TF_FORCE_GPU_ALLOW_GROWTH}
      - TF_GPU_MEMORY_LIMIT=${TF_GPU_MEMORY_LIMIT}
      - TF_GPU_ALLOCATOR=cuda_malloc_async
    command:
    - /usr/local/bin/python
    - -u
    - -m
    - nvflare.private.fed.app.client.client_train
    - -m
    - /workspace
    - -s
    - fed_client.json
    - --set
    - secure_train=true
    - uid=site-3
    - org=nvidia
    - config_folder=config
    volumes:
    - ./site-3:/workspace
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]


  site-4:
    container_name: site-4
    build:
      context: ./nvflare_compose
      dockerfile: Dockerfile
    image: ${DOCKER_IMAGE_SITE}
    ulimits:
      memlock: -1
      stack: 67108864
    environment:
      - TF_FORCE_GPU_ALLOW_GROWTH=${TF_FORCE_GPU_ALLOW_GROWTH}
      - TF_GPU_MEMORY_LIMIT=${TF_GPU_MEMORY_LIMIT}
      - TF_GPU_ALLOCATOR=cuda_malloc_async
    command:
    - /usr/local/bin/python
    - -u
    - -m
    - nvflare.private.fed.app.client.client_train
    - -m
    - /workspace
    - -s
    - fed_client.json
    - --set
    - secure_train=true
    - uid=site-4
    - org=nvidia
    - config_folder=config
    volumes:
    - ./site-4:/workspace
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]


volumes:
  nvflare_svc_persist: null
